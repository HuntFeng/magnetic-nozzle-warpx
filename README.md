# Magnetic Nozzle PIC Simulation in Cylindrical Coordinate

WarpX is able to use CPU or GPU backend. Depending on the choice, we can choose different HPC.

## Niagara (CPU)
### Load modules
```
module purge
module load NiaEnv/2019b intel/2020u4 intelmpi/2020u4 python/3.11.5 ffmpeg/3.4.2 hdf5/1.10.7
```
- hdf5 is to enable WarpX hdf5 output.
- ffmpeg is for making animes. If not planning to make animes, this is optional.
- `match...case...` syntax is used in `post_processing.py`, python version must be `>=3.10`.

### Create virtualenv
```
virtualenv --system-site-packages $HOME/.venvs/warpx
source $HOME/.venvs/warpx/bin/activate
pip install cmake tqdm matplotlib jupyter
```
- cmake is required in the virtualenv since warpx will be compiled and build using cmake.

### Compile WarpX
Download [WarpX-23.11](https://github.com/ECP-WarpX/WarpX/releases/tag/23.11) to Home directory and untar it, then use the `build_warpx.sh` to build WarpX. It is configured to enable RZ coordinate, OMP, python binding (pywarpx), and openpmd (hdf5) output format.

### Testing and debugging
To run the simulation interactively, we need to request some gpu resource first
```
salloc --time=1:00:00 -ntasks=80
```
To run the simulation, simply do
```
source warpx.profile --cpu
srun python run_simulation.py -out <diags_folder> -cpu
```
- The script will need the path to a diagnostics folder `<diags_folder>`.
- If we just need to test the script using small number of cores, we can directly run the following line without requesting any resources,
```
mpirun -np <ntasks> python run_simulation.py -out <diags_folder> -cpu
```


### Use Slurm
To submit a job to Slurm. simply use the slurm script `nozzle`,
```
sbatch nozzle
```

## Narval (GPU)
### Load modules
```
module purge
module load StdEnv/2023 gcc/12.3 openmpi/4.1.5 cuda/12.2 hdf5-mpi/1.14.2 python/3.11.5 mpi4py/3.1.4
```
- cuda is for the gpu related compilations
- mpi4py is an extension to the python module, so no need to install it using pip or conda now

### Create virtualenv
```
virtualenv --system-site-packages $HOME/.venvs/warpx_gpu
source $HOME/.venvs/warpx_gpu/bin/activate
pip install tqdm matplotlib jupyter
```
- no need to install cmake now, because Narval has it by default

### Compile WarpX
Download [WarpX-23.11](https://github.com/ECP-WarpX/WarpX/releases/tag/23.11) to Home directory and untar it, then use the `build_warpx.sh` to build WarpX. It is configured to enable RZ coordinate, CUDA, python binding (pywarpx), and openpmd (hdf5) output format.

### Testing and debugging
To run the simulation interactively, we need to request some gpu resource first
```
salloc --time=1:00:00 --mem=1G --gpus=4
```
- must set the mem to a number larger than the default one, other wise `out of memory error` occurs.

Now we can run the simulation in command line,
```
source warpx.profile --gpu
srun python run_simulation.py -out <diags_folder> -gpu
```
- The script will need the path to a diagnostics folder `<diags_folder>`.

### Use Slurm
To submit a job to Slurm. simply use the slurm script `nozzle`,
```
sbatch nozzle_gpu
```

## Post-Processing
The `post_processing.py` script has everything ready for you.
- To make animes, simply do
```
python post_processing.py <diags_folder>
```
- To make animes, remember to load `ffmpeg` module first
- To draw graphs of certain fields at certain step, check the usage in `analysis.ipynb`.
- If want to diagnose the wall time per step using the `post_processing.py`, set the warpx verbosity to 1 
```
picmi.Simulation(verbose=1)
```
and make sure the warpx standard output is in the diags_folder.

## Files
- `nozzle[_gpu]`: Slurm script to submit job.
- `run_simulation.py`: The input file defines the simulation.
- `magnetic_field.py`: The magnetic field generated by an external coil is defined here.
- `injector.py`: Defines the particle injections per time step.
- `params.py`: Record the parameters used in simulation. 
- `util.py`: Usefule physics formulas are in here.
- `solver.py`: Custom Poisson solvers.
- `post_processing.py`: All data visualization functions are here.
- `analysis.ipynb`: Jupyter notebook for analysing the data.
